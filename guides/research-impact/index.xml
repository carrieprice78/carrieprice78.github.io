<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research Impact | Carrie Price, MLS</title>
    <link>https://carrieprice78.github.io/guides/research-impact/</link>
      <atom:link href="https://carrieprice78.github.io/guides/research-impact/index.xml" rel="self" type="application/rss+xml" />
    <description>Research Impact</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 03 Aug 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://carrieprice78.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Research Impact</title>
      <link>https://carrieprice78.github.io/guides/research-impact/</link>
    </image>
    
    <item>
      <title>Alternative Metrics</title>
      <link>https://carrieprice78.github.io/guides/research-impact/alternative-metrics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://carrieprice78.github.io/guides/research-impact/alternative-metrics/</guid>
      <description>&lt;h2 id=&#34;what-are-alternative-metrics&#34;&gt;What are Alternative Metrics?&lt;/h2&gt;
&lt;p&gt;New technologies like social media and public repositories allow researchers to measure impact beyond the traditional h-index and impact factor. Alternative metrics make an estimate of impact through social media mentions, blog posts, media outlets, shares, saves, and downloads.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Altmetrics look at a variety of inputs, which vary depending on who is doing the measurement and how they have chosen to weigh each input relative to one another (and these complex weighting formulae are usually not disclosed). Typical inputs include activity on social networks and social bookmarking sites, mainstream media and blog coverage, and whether anyone has left any comments on the article.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;sub&gt;Reference: Crotty, D. (2017). Altmetrics. European Heart Journal, 38(35), 2647-2648 &lt;a href=&#34;https://doi.org/10.1093/eurheartj/ehx447&#34;&gt;https://doi.org/10.1093/eurheartj/ehx447&lt;/a&gt;&lt;/sub&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;. . . that dog-eared (but uncited) article that used to live on a shelf now lives in Mendeley, CiteULike, or Zotero, where we can see and count it. That hallway conversation about a recent finding has moved to blogs and social networks–now, we can listen in. The local genomics dataset has moved to an online repository; now, we can track it. This diverse group of activities forms a composite trace of impact far richer than any available before. We call the elements of this trace altmetrics&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;sub&gt;Reference: Priem, J., Taraborelli, D., Groth, P., &amp;amp; Neylon, C. (2010). 
&lt;a href=&#34;http://altmetrics.org/manifesto/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Altmetrics: A manifesto&lt;/a&gt;.&lt;/sub&gt;&lt;/p&gt;
&lt;h3 id=&#34;why-are-alternative-metrics-important&#34;&gt;Why are Alternative Metrics Important?&lt;/h3&gt;
&lt;p&gt;Alternative metrics give authors an immediate way to measure impact. Alternative metrics can provide supplemental measures of assessing impact, dissemination, and reach.&lt;/p&gt;
&lt;p&gt;See our selected tools for alternative metrics. Try a few of the tools and decide for yourself whether alternative metrics add value to your impact.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Researcher and Author Profiles</title>
      <link>https://carrieprice78.github.io/guides/research-impact/researcher-profiles/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://carrieprice78.github.io/guides/research-impact/researcher-profiles/</guid>
      <description>&lt;h2 id=&#34;why-establish-a-researcher-profile&#34;&gt;Why Establish a Researcher Profile?&lt;/h2&gt;
&lt;p&gt;Creating and maintaining a unique public profile for the dissemination and promotion of your research is key to establishing your identity as a researcher. A researcher profile serves as a persistent identifier linking together your scholarly output throughout your career. A research profile can:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Link all variations and changes to your name to one profile&lt;/li&gt;
&lt;li&gt;Disambiguate yourself from other researchers with the same or similar name&lt;/li&gt;
&lt;li&gt;Associate all of your publications throughout your career across multiple departments and institutional affiliations&lt;/li&gt;
&lt;li&gt;Enhance discoverability of your work by potential collaborators&lt;/li&gt;
&lt;li&gt;Make creating publication lists of your work fast and easy&lt;/li&gt;
&lt;li&gt;Allow you to take advantage of enhanced database features, such as tracking your h-index and and other research metrics&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;orcid&#34;&gt;ORCID&lt;/h3&gt;
&lt;p&gt;
&lt;a href=&#34;https://orcid.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ORCID&lt;/a&gt; is an acronym for &amp;ldquo;Open Researcher and Contributor ID.&amp;rdquo; ORCID is an independent, non-profit, community-based registry of unique research identifiers that allows researchers to create and maintain their own researcher profile. Researchers can include their education, work history, citations, and other research output in a single profile. Profile content can be imported by linking your ORCID profile to a Scopus Author ID or the Web of Science Publons, or by manually adding data from PubMed or other sources.&lt;/p&gt;
&lt;h3 id=&#34;sciencv&#34;&gt;SciENcv&lt;/h3&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/sciencv/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SciENcv&lt;/a&gt;, the Science Experts Network Curriculum Vitae, is a researcher profile system for all individuals who apply for, receive, or are associated with research investments from U.S.federal agencies. SciENcv is available in My NCBI.&lt;/p&gt;
&lt;h3 id=&#34;google-scholar&#34;&gt;Google Scholar&lt;/h3&gt;
&lt;p&gt;
&lt;a href=&#34;https://scholar.google.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Scholar&lt;/a&gt; is a search engine that searches the web for scholarly and peer reviewed literature. Google Scholar allows authors to create and maintain a profile page. Sign in to your Google Account and you&amp;rsquo;ll be able to review your profile.&lt;/p&gt;
&lt;h3 id=&#34;scopus&#34;&gt;Scopus&lt;/h3&gt;
&lt;p&gt;Scopus, a blbliographic literature database from Elsevier, automatically creates an Author ID for authors as new citations are added to the database. An algorithm attempts to link citations with similar attributes to an Author ID. You can find your Author ID and make any corrections to the citations associated with your profile.&lt;/p&gt;
&lt;h3 id=&#34;publons-from-clarivate-analytics&#34;&gt;Publons from Clarivate Analytics&lt;/h3&gt;
&lt;p&gt;
&lt;a href=&#34;https://publons.com/about/home/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Publons (formerly ResearcherID)&lt;/a&gt; is the peer review activity tracker and researcher profile solution developed by Clarivate Analytics, the parent company of the Web of Science database. Upon registering, you are assigned a unique identifier you can use to manage your publication list, track citations to your work, and view your h-index, as well as a record of your work as a peer reviewer.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Responsible Use</title>
      <link>https://carrieprice78.github.io/guides/research-impact/responsible-use/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://carrieprice78.github.io/guides/research-impact/responsible-use/</guid>
      <description>&lt;h2 id=&#34;the-leiden-manifesto&#34;&gt;The Leiden Manifesto&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;http://www.leidenmanifesto.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Leiden Manifesto for Research Metrics&lt;/a&gt; was published in 2015 by five experts urging responsible use in metrics, named after the conference where the idea came to fruition. They promote the following ten principles to guide research evaluation:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Quantitative evaluation should support qualitative, expert assessment.&lt;/li&gt;
&lt;li&gt;Measure performance against the research missions of the institution, group, or researcher.&lt;/li&gt;
&lt;li&gt;Protect excellence in locally relevant research.&lt;/li&gt;
&lt;li&gt;Keep data collection and analytical processes open, transparent, and simple.&lt;/li&gt;
&lt;li&gt;Allow those evaluated to verify data and analysis.&lt;/li&gt;
&lt;li&gt;Account for variation by field in publication and citation practices.&lt;/li&gt;
&lt;li&gt;Base assessment of individual researchers on a qualitative judgment of their portfolio.&lt;/li&gt;
&lt;li&gt;Avoid misplaced concreteness and false precision.&lt;/li&gt;
&lt;li&gt;Recognize the systemic effects of assessment and indicators.&lt;/li&gt;
&lt;li&gt;Scrutinize indicators regularly and update them.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Hicks, D., Wouters, P., Waltman, L., de Rijcke, S., &amp;amp; Rafols, I. (2015). Bibliometrics: The Leiden Manifesto for research metrics. Nature News 520(7548), 429–431. &lt;a href=&#34;https://doi.org/10.1038/520429a&#34;&gt;https://doi.org/10.1038/520429a&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;metric-tide-report&#34;&gt;Metric Tide Report&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://responsiblemetrics.org/the-metric-tide/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Metric Tide Report&lt;/a&gt;, published in 2015 commissioned by the Higher Education Funding Council for England (UK), is a report of the independent review of the role of metrics in research assessment and management. Traditional metrics have long been used as indicators for research and researcher impact. Their use can be problematic when taken out of context with uncritical acceptance. Responsible metrics should be considered and understood in the following dimensions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Robustness&lt;/strong&gt; - Is the metric using the best available and accurate data?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Humility&lt;/strong&gt; - Quantitative evaluation can complement, but not replace, expert assessment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transparency&lt;/strong&gt; - Is the collection of data and its analysis open to scrutiny?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Diversity&lt;/strong&gt; - Does the metric represent the landscape of research in any given field, and use appropriate indicators to support research and researchers?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reflexivity&lt;/strong&gt; - Is the use of bibliometric analysis dynamic and open to change?&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Metrics evoke a mixed reaction from the research community. A commitment to using data and evidence to inform decisions makes many of us sympathetic, even enthusiastic, about the prospect of granular, real-time analysis of our own activities. If we as a sector can’t take full advantage of the possibilities of big data, then who can?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Wilsdon, J., et al. (2015). The Metric Tide: Report of the Independent Review of the Role of Metrics in Research Assessment and Management. &lt;a href=&#34;https://doi.org/10.13140/RG.2.1.4929.1363&#34;&gt;https://doi.org/10.13140/RG.2.1.4929.1363&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;sf-dora&#34;&gt;SF DORA&lt;/h2&gt;
&lt;p&gt;SF DORA&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sfdora.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The San Francisco Declaration on Research Assessment (SF DORA)&lt;/a&gt; recognizes the need to improve the ways in which the outputs of scholarly research are evaluated. The declaration was developed in 2012 during the Annual Meeting of the American Society for Cell Biology.&lt;/p&gt;
&lt;p&gt;The declaration is a worldwide initiative covering all scholarly disciplines and stakeholders.&lt;/p&gt;
&lt;p&gt;Signing the 2013 San Francisco Declaration on Research Assessment (DORA) is an important  way for individuals and organizations to publicly acknowledge their commitment to improve research by strengthening research assessment.&lt;/p&gt;
&lt;p&gt;The DORA roadmap for the next two years will focus on three strategic goals to enable signatories to take action:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Increase awareness of the need to develop credible alternatives to the inappropriate uses of metrics in research assessment.&lt;/li&gt;
&lt;li&gt;Research and promote tools and processes that facilitate best practice in research assessment.&lt;/li&gt;
&lt;li&gt;Extend the reach and impact of DORA’s work across scholarly disciplines and in new areas of the world.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;From SF DORA at 
&lt;a href=&#34;https://sfdora.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;www.sfdora.org&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Read the declaration at SF DORA: &lt;a href=&#34;https://sfdora.org/read/&#34;&gt;https://sfdora.org/read/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Sign the declaration at SF DORA: &lt;a href=&#34;https://sfdora.org/sign/&#34;&gt;https://sfdora.org/sign/&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;further-reading-on-responsible-use-a-selected-bibliography&#34;&gt;Further Reading on Responsible Use: A Selected Bibliography&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Adair, S. M. (2006). Ethics in publishing: ghostwriting, conflicts of interest, and the impact factor. Pediatric Dentistry, 28(4), 309. Retrieved from &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/16903437&#34;&gt;https://www.ncbi.nlm.nih.gov/pubmed/16903437&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Alberts, B. (2013). Impact factor distortions. Science, 340(6134), 787. &lt;a href=&#34;https://doi.org/10.1126/science.1240319&#34;&gt;https://doi.org/10.1126/science.1240319&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Bohannon, J. (2016). Hate journal impact factors? New study gives you one more reason. Science. &lt;a href=&#34;https://doi.org/10.1126/science.aag0643&#34;&gt;https://doi.org/10.1126/science.aag0643&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Charlier, P., Bridoux, V., Watier, L., Ménétrier, M., de la Grandmaison, G. L., Hervé, C. (2012). Ethics requirements and impact factor. Journal of Medical Ethics, 38(4), 253–255. &lt;a href=&#34;https://doi.org/10.1136/medethics-2011-100174&#34;&gt;https://doi.org/10.1136/medethics-2011-100174&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Curry, S. (2018). Let’s move beyond the rhetoric: it&amp;rsquo;s time to change how we judge research. Nature, 554(7691), 147. &lt;a href=&#34;https://doi.org/10.1038/d41586-018-01642-w&#34;&gt;https://doi.org/10.1038/d41586-018-01642-w&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gallagher, A. (2011). The ethics of impact factors. Nursing Ethics, 18(1), 3–5. &lt;a href=&#34;https://doi.org/10.1177/0969733010388353&#34;&gt;https://doi.org/10.1177/0969733010388353&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Heyeres, M., Tsey, K., Yang, Y., Yan, L., &amp;amp; Jiang, H. (2018). The characteristics and reporting quality of research impact case studies: A systematic review. Evaluation and Program Planning, 73, 10–23. &lt;a href=&#34;https://doi.org/10.1016/j.evalprogplan.2018.11.002&#34;&gt;https://doi.org/10.1016/j.evalprogplan.2018.11.002&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hicks, D., Wouters, P., Waltman, L., de Rijcke, S., &amp;amp; Rafols, I. (2015). Bibliometrics: The Leiden Manifesto for research metrics. Nature, 520(7548), 429–431. &lt;a href=&#34;https://doi.org/10.1038/520429a&#34;&gt;https://doi.org/10.1038/520429a&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Huggett, S. (2013). Journal bibliometrics indicators and citation ethics: a discussion of current issues. Atherosclerosis, 230(2), 275–277. &lt;a href=&#34;https://doi.org/10.1016/j.atherosclerosis.2013.07.051&#34;&gt;https://doi.org/10.1016/j.atherosclerosis.2013.07.051&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jones, J. F. X. (2013). The impact of impact factors and the ethics of publication. Irish Journal of Medical Science, 182(4), 541. &lt;a href=&#34;https://doi.org/10.1007/s11845-013-1014-y&#34;&gt;https://doi.org/10.1007/s11845-013-1014-y&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Simons, K. (2008). The misused impact factor. Science, 322(5899), 165. &lt;a href=&#34;https://doi.org/10.1126/science.1165316&#34;&gt;https://doi.org/10.1126/science.1165316&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Teixeira da Silva, J. A. (2017). The ethics of peer and editorial requests for self-citation of their work and journal. Armed Forces Medical Journal, India, 73(2), 181–183. &lt;a href=&#34;https://doi.org/10.1016/j.mjafi.2016.11.008&#34;&gt;https://doi.org/10.1016/j.mjafi.2016.11.008&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
